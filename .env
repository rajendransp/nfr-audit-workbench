# ==============================================================================
# POCKET FLOW - LLM Configuration
# ==============================================================================
# 
# Choose ONE of the following options and uncomment the corresponding section:
#
# ==============================================================================
# OPTION 1: OpenAI API (GPT-4, GPT-3.5, etc.)
# ==============================================================================
# Get your API key from: https://platform.openai.com/api-keys
# Uncomment the line below and replace with your actual API key:
# OPENAI_API_KEY=
# Optional: Specify the model (defaults to gpt-4o-mini for cost efficiency)
# OPENAI_MODEL=gpt-4o-mini

# ==============================================================================
# OPTION 2: Google Gemini API (Free tier available)
# ==============================================================================
# Get your API key from: https://ai.google.dev/
# Uncomment the line below and replace with your actual API key:
# GEMINI_API_KEY=

# Optional: Specify the model (defaults to gemini-1.5-flash)
# Available models: gemini-1.5-flash, gemini-1.5-pro, gemini-2.0-flash
# GEMINI_MODEL=gemini-1.5-flash

#
# ==============================================================================
# OPTION 3: Ollama (Free, Open-Source, Runs Locally) - RECOMMENDED
# ==============================================================================
# Prerequisites: Download and run Ollama from https://ollama.ai
#   1. Download Ollama from https://ollama.ai
#   2. Run: ollama serve
#   3. In another terminal: ollama pull mistral
#
# Uncomment and configure the following:
# LLM_PROVIDER=OLLAMA
# OLLAMA_MODEL=gemma3:12b
# OLLAMA_BASE_URL=http://localhost:11434
# OLLAMA_API_KEY=

LLM_PROVIDER=OLLAMA
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=qwen3-coder:30b

#
# ==============================================================================
# OPTION 3: XAI (Grok)
# ==============================================================================
# Get your API key from: https://console.x.ai/
# Uncomment and configure the following:
# LLM_PROVIDER=XAI
# XAI_MODEL=grok-beta
# XAI_BASE_URL=https://api.x.ai/v1
# XAI_API_KEY=your-xai-api-key-here

#
# ==============================================================================
# OPTION 4: OpenRouter (Multi-Model Gateway)
# ==============================================================================
# Get your API key from: https://openrouter.ai/
# Uncomment and configure the following:
# LLM_PROVIDER=OPENROUTER
# OPENROUTER_MODEL=mistralai/mixtral-8x7b-instruct
# OPENROUTER_BASE_URL=https://openrouter.ai/api/v1
# OPENROUTER_API_KEY=your-openrouter-api-key-here

#
# ==============================================================================
# GITHUB TOKEN (Optional but recommended for higher API limits)
# ==============================================================================
# Get your token from: https://github.com/settings/tokens
# Required for private repositories, optional for public ones
# GITHUB_TOKEN=your-github-token-here

#
# ==============================================================================
# LOGGING (Optional)
# ==============================================================================
# Directory to store LLM call logs (defaults to './logs')
# LOG_DIR=logs
